from ultralytics import YOLO
import torch

# æ£€æŸ¥CUDAå¯ç”¨æ€§
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")

# Load a pretrained YOLO11n model
model = YOLO("yolo11n.pt")

# Train the model on the COCO8 dataset with improved configuration
train_results = model.train(
    data="coco8.yaml",          # Path to dataset configuration file
    epochs=100,                 # Number of training epochs
    imgsz=640,                  # Image size for training
    device="0",                 # Device to run on (e.g., 'cpu', 0, [0,1,2,3])
    
    # === æ€§èƒ½ä¼˜åŒ–å‚æ•° ===
    batch=16,                   # æ‰¹æ¬¡å¤§å°ï¼Œæ ¹æ®GPUå†…å­˜è°ƒæ•´
    cache=True,                 # ç¼“å­˜æ•°æ®é›†åˆ°ç£ç›˜ï¼Œæ˜¾è‘—æå‡è®­ç»ƒé€Ÿåº¦
    workers=8,                  # æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°
    amp=True,                   # è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒï¼ŒèŠ‚çœæ˜¾å­˜
    
    # === è®­ç»ƒæ§åˆ¶å‚æ•° ===
    patience=30,                # æ—©åœè€å¿ƒå€¼ï¼Œ30ä¸ªepochæ— æ”¹å–„ååœæ­¢
    save_period=25,             # æ¯25ä¸ªepochä¿å­˜ä¸€æ¬¡æ¨¡å‹
    val=True,                   # è®­ç»ƒæœŸé—´è¿›è¡ŒéªŒè¯
    plots=True,                 # ç”Ÿæˆè®­ç»ƒå›¾è¡¨å’Œå¯è§†åŒ–
    verbose=True,               # è¯¦ç»†è¾“å‡ºè®­ç»ƒä¿¡æ¯
    
    # === å­¦ä¹ ç‡å’Œä¼˜åŒ–å™¨ ===
    lr0=0.01,                   # åˆå§‹å­¦ä¹ ç‡
    lrf=0.01,                   # æœ€ç»ˆå­¦ä¹ ç‡ = lr0 * lrf
    momentum=0.937,             # SGDåŠ¨é‡
    weight_decay=0.0005,        # æƒé‡è¡°å‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
    warmup_epochs=3.0,          # å­¦ä¹ ç‡é¢„çƒ­è½®æ•°
    cos_lr=False,               # æ˜¯å¦ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦
    
    # === æ•°æ®å¢å¼ºå‚æ•° ===
    hsv_h=0.015,                # è‰²è°ƒå¢å¼ºèŒƒå›´
    hsv_s=0.7,                  # é¥±å’Œåº¦å¢å¼ºèŒƒå›´
    hsv_v=0.4,                  # æ˜åº¦å¢å¼ºèŒƒå›´
    degrees=0.0,                # æ—‹è½¬è§’åº¦èŒƒå›´ (+/-deg)
    translate=0.1,              # å¹³ç§»èŒƒå›´ (+/-fraction)
    scale=0.5,                  # ç¼©æ”¾èŒƒå›´ (+/-gain)
    fliplr=0.5,                 # æ°´å¹³ç¿»è½¬æ¦‚ç‡
    mosaic=1.0,                 # é©¬èµ›å…‹å¢å¼ºæ¦‚ç‡
    mixup=0.0,                  # æ··åˆå¢å¼ºæ¦‚ç‡
    
    # === æŸå¤±å‡½æ•°æƒé‡ ===
    box=7.5,                    # è¾¹ç•Œæ¡†æŸå¤±æƒé‡
    cls=0.5,                    # åˆ†ç±»æŸå¤±æƒé‡
    dfl=1.5,                    # DFLæŸå¤±æƒé‡
    
    # === é¡¹ç›®ç®¡ç† ===
    project='yolo_training',    # é¡¹ç›®ç›®å½•åç§°
    name='coco8_run',           # å®éªŒåç§°
    
    # === é«˜çº§è®¾ç½® ===
    seed=42,                    # éšæœºç§å­ï¼Œä¿è¯å¯é‡å¤æ€§
    deterministic=True,         # ç¡®å®šæ€§è®­ç»ƒ
    resume=False,               # æ˜¯å¦ä»ä¸Šæ¬¡æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
)

print(f"\nè®­ç»ƒå®Œæˆï¼æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {train_results}")

# Evaluate the model's performance on the validation set
print("\nå¼€å§‹éªŒè¯æ¨¡å‹æ€§èƒ½...")
metrics = model.val()
print(f"mAP50: {metrics.box.map50:.4f}")
print(f"mAP50-95: {metrics.box.map:.4f}")

# Perform object detection on an image
print("\næµ‹è¯•å›¾åƒé¢„æµ‹...")
try:
    results = model("test_image.jpg")  # Predict on an image
    results[0].show()  # Display results
    print("é¢„æµ‹å®Œæˆï¼Œç»“æœå·²æ˜¾ç¤º")
    
    # === æŸ¥çœ‹æ¨¡å‹çš„ç›´æ¥è¾“å‡ºæ•°æ® ===
    print("\n=== æ¨¡å‹ç›´æ¥è¾“å‡ºæ•°æ®åˆ†æ ===")
    
    # è·å–åŸå§‹PyTorchæ¨¡å‹
    raw_model = model.model
    
    # å‡†å¤‡è¾“å…¥æ•°æ®ï¼ˆæ¨¡æ‹ŸYOLOé¢„å¤„ç†ï¼‰
    import cv2
    img = cv2.imread("test_image.jpg")
    if img is not None:
        print(f"åŸå§‹å›¾åƒå°ºå¯¸: {img.shape}")
        
        # YOLOé¢„å¤„ç†
        img_resized = cv2.resize(img, (640, 640))
        img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0
        img_tensor = img_tensor.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
        
        # ç¡®ä¿å¼ é‡åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼ˆGPUæˆ–CPUï¼‰
        device = next(raw_model.parameters()).device
        img_tensor = img_tensor.to(device)
        
        print(f"é¢„å¤„ç†åå¼ é‡å½¢çŠ¶: {img_tensor.shape}")
        print(f"å¼ é‡è®¾å¤‡: {img_tensor.device}")
        print(f"æ¨¡å‹è®¾å¤‡: {device}")
        
        # è·å–æ¨¡å‹åŸå§‹è¾“å‡º
        with torch.no_grad():
            raw_outputs = raw_model(img_tensor)
        
        print(f"\næ¨¡å‹åŸå§‹è¾“å‡ºä¿¡æ¯:")
        print(f"è¾“å‡ºæ•°é‡: {len(raw_outputs)}")
        
        for i, output in enumerate(raw_outputs):
            # æ£€æŸ¥è¾“å‡ºç±»å‹
            if isinstance(output, torch.Tensor):
                print(f"è¾“å‡º {i}: å¼ é‡ï¼Œå½¢çŠ¶ {output.shape}")
                print(f"  æ•°æ®ç±»å‹: {output.dtype}")
                print(f"  è®¾å¤‡: {output.device}")
                print(f"  æ•°å€¼èŒƒå›´: [{output.min().item():.6f}, {output.max().item():.6f}]")
                print(f"  å¹³å‡å€¼: {output.mean().item():.6f}")
            elif isinstance(output, list):
                print(f"è¾“å‡º {i}: åˆ—è¡¨ï¼ŒåŒ…å« {len(output)} ä¸ªå…ƒç´ ")
                for j, item in enumerate(output):
                    if isinstance(item, torch.Tensor):
                        print(f"  åˆ—è¡¨å…ƒç´  {j}: å¼ é‡ï¼Œå½¢çŠ¶ {item.shape}")
                        print(f"    æ•°æ®ç±»å‹: {item.dtype}")
                        print(f"    è®¾å¤‡: {item.device}")
                        print(f"    æ•°å€¼èŒƒå›´: [{item.min().item():.6f}, {item.max().item():.6f}]")
                        print(f"    å¹³å‡å€¼: {item.mean().item():.6f}")
                    else:
                        print(f"  åˆ—è¡¨å…ƒç´  {j}: ç±»å‹ {type(item)}")
            else:
                print(f"è¾“å‡º {i}: æœªçŸ¥ç±»å‹ {type(output)}")
            
            # è¯¦ç»†åˆ†æä¸»è¦è¾“å‡ºå¼ é‡
            if i == 0 and isinstance(output, torch.Tensor):  # ä¸»è¦æ£€æµ‹è¾“å‡º
                try:
                    if len(output.shape) == 3:
                        batch_size, channels, num_anchors = output.shape
                        print(f"\n=== ä¸»è¦è¾“å‡ºå¼ é‡è¯¦ç»†åˆ†æ ===")
                        print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
                        print(f"ç‰¹å¾é€šé“æ•°: {channels} (åŒ…å«åæ ‡+ç±»åˆ«+å…¶ä»–ç‰¹å¾)")
                        print(f"é”šç‚¹æ€»æ•°: {num_anchors}")
                        
                        # åˆ†æä¸åŒéƒ¨åˆ†çš„æ•°æ®
                        output_data = output[0]  # å»é™¤batchç»´åº¦
                        
                        # åæ ‡ä¿¡æ¯ (å‰4ä¸ªé€šé“)
                        if channels >= 4:
                            coords = output_data[:4, :]
                            print(f"\nåæ ‡ä¿¡æ¯ (å‰4ä¸ªé€šé“):")
                            print(f"  Xåæ ‡èŒƒå›´: [{coords[0].min().item():.3f}, {coords[0].max().item():.3f}]")
                            print(f"  Yåæ ‡èŒƒå›´: [{coords[1].min().item():.3f}, {coords[1].max().item():.3f}]")
                            print(f"  å®½åº¦èŒƒå›´: [{coords[2].min().item():.3f}, {coords[2].max().item():.3f}]")
                            print(f"  é«˜åº¦èŒƒå›´: [{coords[3].min().item():.3f}, {coords[3].max().item():.3f}]")
                        
                        # ç±»åˆ«æ¦‚ç‡ä¿¡æ¯ (COCOæœ‰80ä¸ªç±»åˆ«)
                        if channels >= 84:  # 4ä¸ªåæ ‡ + 80ä¸ªç±»åˆ«
                            class_probs = output_data[4:84, :]
                            print(f"\nç±»åˆ«æ¦‚ç‡ä¿¡æ¯ (80ä¸ªCOCOç±»åˆ«):")
                            print(f"  æ¦‚ç‡èŒƒå›´: [{class_probs.min().item():.6f}, {class_probs.max().item():.6f}]")
                            print(f"  å¹³å‡æ¦‚ç‡: {class_probs.mean().item():.6f}")
                            
                            # æ‰¾åˆ°ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹
                            max_class_scores, max_class_indices = torch.max(class_probs, dim=0)
                            top_conf_idx = torch.argmax(max_class_scores)
                            
                            print(f"\nç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹:")
                            print(f"  é”šç‚¹ç´¢å¼•: {top_conf_idx.item()}")
                            print(f"  æœ€é«˜ç½®ä¿¡åº¦: {max_class_scores[top_conf_idx].item():.6f}")
                            print(f"  é¢„æµ‹ç±»åˆ«ID: {max_class_indices[top_conf_idx].item()}")
                            if channels >= 4:
                                print(f"  å¯¹åº”åæ ‡: x={coords[0, top_conf_idx].item():.3f}, "
                                      f"y={coords[1, top_conf_idx].item():.3f}, "
                                      f"w={coords[2, top_conf_idx].item():.3f}, "
                                      f"h={coords[3, top_conf_idx].item():.3f}")
                        
                        # é”šç‚¹åˆ†å¸ƒåˆ†æ
                        print(f"\né”šç‚¹åˆ†å¸ƒåˆ†æ:")
                        print(f"8400ä¸ªé”šç‚¹æ¥è‡ªä¸åŒå°ºåº¦çš„ç‰¹å¾å›¾:")
                        print(f"  - 80Ã—80 ç‰¹å¾å›¾: 6400ä¸ªé”šç‚¹ (ç»†ç²’åº¦æ£€æµ‹)")
                        print(f"  - 40Ã—40 ç‰¹å¾å›¾: 1600ä¸ªé”šç‚¹ (ä¸­ç­‰å°ºåº¦æ£€æµ‹)")
                        print(f"  - 20Ã—20 ç‰¹å¾å›¾: 400ä¸ªé”šç‚¹ (å¤§ç›®æ ‡æ£€æµ‹)")
                        print(f"  æ€»è®¡: 6400 + 1600 + 400 = 8400 ä¸ªé”šç‚¹")
                    else:
                        print(f"\nâš ï¸  è¾“å‡ºå¼ é‡ç»´åº¦ä¸ç¬¦åˆé¢„æœŸ: {output.shape}")
                        print("   é¢„æœŸ: 3ç»´å¼ é‡ [batch_size, channels, num_anchors]")
                        
                except Exception as e:
                    print(f"\nâŒ åˆ†æä¸»è¦è¾“å‡ºå¼ é‡æ—¶å‡ºé”™: {e}")
                    print(f"   è¾“å‡ºå¼ é‡å½¢çŠ¶: {output.shape}")
                    print(f"   è¾“å‡ºå¼ é‡ç±»å‹: {type(output)}")
        
        print(f"\n=== YOLO11åŒè¾“å‡ºç»“æ„è¯´æ˜ ===")
        print("ğŸ¯ è¾“å‡º0: ä¸»è¦æ£€æµ‹ç»“æœ")
        print("  - å½¢çŠ¶: [1, 84, 8400]")
        print("  - 84ä¸ªé€šé“ = 4ä¸ªåæ ‡ç‰¹å¾ + 80ä¸ªç±»åˆ«æ¦‚ç‡")
        print("  - 8400ä¸ªé”šç‚¹æ¥è‡ª3ä¸ªå°ºåº¦ç‰¹å¾å›¾çš„åˆå¹¶")
        print("  - ç”¨æˆ·å‹å¥½çš„ç®€åŒ–è¾“å‡º")
        print()
        print("ğŸ¯ è¾“å‡º1: åŸå§‹ç‰¹å¾å›¾åˆ—è¡¨")
        print("  - åŒ…å«3ä¸ªå¼ é‡çš„åˆ—è¡¨")
        print("  - å¼ é‡0: [1, 144, 80, 80] - é«˜åˆ†è¾¨ç‡ç‰¹å¾")
        print("  - å¼ é‡1: [1, 144, 40, 40] - ä¸­åˆ†è¾¨ç‡ç‰¹å¾") 
        print("  - å¼ é‡2: [1, 144, 20, 20] - ä½åˆ†è¾¨ç‡ç‰¹å¾")
        print("  - 144ä¸ªé€šé“åŒ…å«å®Œæ•´è®­ç»ƒç‰¹å¾(å«DFL)")
        print("  - ç”¨äºè°ƒè¯•å’Œé«˜çº§åº”ç”¨")
        print()
        print("=== åå¤„ç†ç®—æ³•è¯´æ˜ ===")
        print("1. ç½®ä¿¡åº¦è¿‡æ»¤: ä¿ç•™ç½®ä¿¡åº¦ > threshold çš„æ£€æµ‹")
        print("2. åæ ‡è§£ç : å°†ç›¸å¯¹åæ ‡è½¬æ¢ä¸ºç»å¯¹åƒç´ åæ ‡")
        print("3. NMS(éæå¤§å€¼æŠ‘åˆ¶): ç§»é™¤é‡å çš„æ£€æµ‹æ¡†")
        print("4. åæ ‡ç¼©æ”¾: å°†640Ã—640å°ºå¯¸çš„åæ ‡ç¼©æ”¾åˆ°åŸå›¾å°ºå¯¸")
        
    else:
        print("æ— æ³•è¯»å–æµ‹è¯•å›¾åƒï¼Œè·³è¿‡ç›´æ¥è¾“å‡ºåˆ†æ")
        
except Exception as e:
    print(f"é¢„æµ‹å¤±è´¥: {e}")
    print("æç¤º: è¯·ç¡®ä¿test_image.jpgæ–‡ä»¶å­˜åœ¨")

# ================================
# å¤šæ ¼å¼æ¨¡å‹å¯¼å‡ºæ¼”ç¤º
# ================================
print("\n" + "="*50)
print("å¼€å§‹å¤šæ ¼å¼æ¨¡å‹å¯¼å‡º")
print("="*50)

# å®šä¹‰è¦å¯¼å‡ºçš„æ ¼å¼åŠå…¶ç”¨é€”
export_formats = {
    # é€šç”¨æ ¼å¼
    "onnx": {
        "name": "ONNX",
        "description": "å¼€æ”¾ç¥ç»ç½‘ç»œäº¤æ¢æ ¼å¼ - è·¨å¹³å°é€šç”¨",
        "performance": "CPUæ¨ç†æå‡3å€é€Ÿåº¦",
        "use_case": "è·¨å¹³å°éƒ¨ç½²ã€ç”Ÿäº§ç¯å¢ƒé¦–é€‰"
    },
    "torchscript": {
        "name": "TorchScript", 
        "description": "PyTorchåºåˆ—åŒ–æ ¼å¼",
        "performance": "åŸç”ŸPyTorchæ€§èƒ½",
        "use_case": "PyTorchç”Ÿæ€ç³»ç»Ÿéƒ¨ç½²"
    },
    
    # é«˜æ€§èƒ½æ ¼å¼
    "engine": {
        "name": "TensorRT",
        "description": "NVIDIA GPUä¼˜åŒ–å¼•æ“",
        "performance": "GPUæ¨ç†æå‡5å€é€Ÿåº¦", 
        "use_case": "NVIDIA GPUæœåŠ¡å™¨éƒ¨ç½²"
    },
    "openvino": {
        "name": "OpenVINO",
        "description": "Intel CPU/GPUä¼˜åŒ–å¼•æ“",
        "performance": "Intelç¡¬ä»¶æå‡3å€é€Ÿåº¦",
        "use_case": "Intel CPU/GPUéƒ¨ç½²"
    },
    
    # ç§»åŠ¨ç«¯æ ¼å¼
    "tflite": {
        "name": "TensorFlow Lite",
        "description": "ç§»åŠ¨è®¾å¤‡è½»é‡åŒ–æ ¼å¼", 
        "performance": "ç§»åŠ¨è®¾å¤‡ä¼˜åŒ–",
        "use_case": "Android/iOSç§»åŠ¨åº”ç”¨"
    },
    "coreml": {
        "name": "CoreML",
        "description": "Appleè®¾å¤‡ä¼˜åŒ–æ ¼å¼",
        "performance": "iOS/macOSåŸç”Ÿä¼˜åŒ–",
        "use_case": "iPhone/iPad/Macåº”ç”¨"
    },
    
    # Webéƒ¨ç½²æ ¼å¼
    "tfjs": {
        "name": "TensorFlow.js",
        "description": "æµè§ˆå™¨JavaScriptæ ¼å¼",
        "performance": "æµè§ˆå™¨å†…æ¨ç†",
        "use_case": "ç½‘é¡µå®æ—¶AIåº”ç”¨"
    }
}

# å¯¼å‡ºæ¨¡å‹åˆ°å„ç§æ ¼å¼
exported_models = {}
print(f"\nå¼€å§‹å¯¼å‡ºè®­ç»ƒå¥½çš„æ¨¡å‹åˆ° {len(export_formats)} ç§æ ¼å¼...")

for format_key, format_info in export_formats.items():
    print(f"\nğŸ“¦ æ­£åœ¨å¯¼å‡º {format_info['name']} æ ¼å¼...")
    print(f"   ğŸ“ æè¿°: {format_info['description']}")
    print(f"   âš¡ æ€§èƒ½: {format_info['performance']}")
    print(f"   ğŸ¯ ç”¨é€”: {format_info['use_case']}")
    
    try:
        # æ ¹æ®æ ¼å¼è®¾ç½®ç‰¹å®šå‚æ•°
        export_args = {"format": format_key}
        
        # ä¸ºä¸åŒæ ¼å¼æ·»åŠ ä¼˜åŒ–å‚æ•°
        if format_key == "onnx":
            export_args.update({
                "simplify": True,    # ç®€åŒ–æ¨¡å‹å›¾
                "dynamic": True,     # æ”¯æŒåŠ¨æ€è¾“å…¥å°ºå¯¸
                "half": False        # ä½¿ç”¨FP32ç²¾åº¦
            })
        elif format_key == "engine":  # TensorRT
            export_args.update({
                "half": True,        # ä½¿ç”¨FP16ç²¾åº¦åŠ é€Ÿ
                "dynamic": True,     # åŠ¨æ€è¾“å…¥å°ºå¯¸
                "workspace": 4       # å·¥ä½œç©ºé—´å¤§å°(GB)
            })
        elif format_key == "tflite":
            export_args.update({
                "int8": False,       # æ˜¯å¦ä½¿ç”¨INT8é‡åŒ–
                "half": False        # ä¿æŒFP32ç²¾åº¦
            })
        elif format_key == "coreml":
            export_args.update({
                "half": True,        # ä½¿ç”¨FP16ç²¾åº¦
                "int8": False        # ä¸ä½¿ç”¨INT8é‡åŒ–
            })
        
        # æ‰§è¡Œå¯¼å‡º
        export_path = model.export(**export_args)
        exported_models[format_key] = {
            "path": export_path,
            "info": format_info
        }
        print(f"   âœ… æˆåŠŸå¯¼å‡ºåˆ°: {export_path}")
        
    except Exception as e:
        print(f"   âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")
        # æŸäº›æ ¼å¼å¯èƒ½éœ€è¦ç‰¹å®šçš„ä¾èµ–æˆ–ç¡¬ä»¶æ”¯æŒ
        if "TensorRT" in str(e):
            print(f"   ğŸ’¡ æç¤º: TensorRTéœ€è¦NVIDIA GPUå’Œç›¸åº”é©±åŠ¨")
        elif "CoreML" in str(e):
            print(f"   ğŸ’¡ æç¤º: CoreMLä¸»è¦åœ¨macOSä¸Šæ”¯æŒ")
        elif "OpenVINO" in str(e):
            print(f"   ğŸ’¡ æç¤º: éœ€è¦å®‰è£…OpenVINOå·¥å…·åŒ…")

# è¾“å‡ºå¯¼å‡ºæ€»ç»“
print(f"\n" + "="*50)
print("ğŸ“‹ å¯¼å‡ºç»“æœæ€»ç»“")
print("="*50)

success_count = len(exported_models)
total_count = len(export_formats)

print(f"âœ… æˆåŠŸå¯¼å‡º: {success_count}/{total_count} ç§æ ¼å¼")

if exported_models:
    print(f"\nğŸ“ å·²å¯¼å‡ºçš„æ¨¡å‹æ–‡ä»¶:")
    for format_key, model_info in exported_models.items():
        print(f"   â€¢ {model_info['info']['name']}: {model_info['path']}")

# ä½¿ç”¨å»ºè®®
print(f"\nğŸ¯ éƒ¨ç½²å»ºè®®:")
print(f"â€¢ ğŸ–¥ï¸  CPUæœåŠ¡å™¨: ä½¿ç”¨ ONNX æˆ– OpenVINO æ ¼å¼")
print(f"â€¢ ğŸš€ NVIDIA GPU: ä½¿ç”¨ TensorRT æ ¼å¼ (æœ€é«˜æ€§èƒ½)")
print(f"â€¢ ğŸ“± ç§»åŠ¨åº”ç”¨: Androidç”¨TFLite, iOSç”¨CoreML")
print(f"â€¢ ğŸŒ Webåº”ç”¨: ä½¿ç”¨ TensorFlow.js æ ¼å¼")
print(f"â€¢ ğŸ”§ å¼€å‘æµ‹è¯•: ä½¿ç”¨ TorchScript æˆ– ONNX æ ¼å¼")

# æ€§èƒ½å¯¹æ¯”æç¤º
print(f"\nâš¡ æ€§èƒ½æå‡å¯¹æ¯” (ç›¸å¯¹äºåŸå§‹PyTorch):")
print(f"â€¢ TensorRT (GPU): é«˜è¾¾5å€é€Ÿåº¦æå‡")
print(f"â€¢ ONNX (CPU): é«˜è¾¾3å€é€Ÿåº¦æå‡") 
print(f"â€¢ OpenVINO (Intel): é«˜è¾¾3å€é€Ÿåº¦æå‡")
print(f"â€¢ TFLite/CoreML: ç§»åŠ¨è®¾å¤‡ä¸“é¡¹ä¼˜åŒ–")

print("\n=== è®­ç»ƒæµç¨‹å®Œæˆ ===")
print("æ£€æŸ¥ä»¥ä¸‹ç›®å½•è·å–è®­ç»ƒç»“æœ:")
print("- yolo_training/coco8_run/weights/ (æ¨¡å‹æƒé‡)")
print("- yolo_training/coco8_run/ (è®­ç»ƒå›¾è¡¨å’Œæ—¥å¿—)")
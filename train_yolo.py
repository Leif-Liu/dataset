from ultralytics import YOLO
import torch

# æ£€æŸ¥CUDAå¯ç”¨æ€§
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")

# Load a pretrained YOLO11n model
model = YOLO("yolo11n.pt")

# Train the model on the COCO8 dataset with improved configuration
train_results = model.train(
    data="coco8.yaml",          # Path to dataset configuration file
    epochs=100,                 # Number of training epochs
    imgsz=640,                  # Image size for training
    device="0",                 # Device to run on (e.g., 'cpu', 0, [0,1,2,3])
    
    # === æ€§èƒ½ä¼˜åŒ–å‚æ•° ===
    batch=16,                   # æ‰¹æ¬¡å¤§å°ï¼Œæ ¹æ®GPUå†…å­˜è°ƒæ•´
    cache=True,                 # ç¼“å­˜æ•°æ®é›†åˆ°ç£ç›˜ï¼Œæ˜¾è‘—æå‡è®­ç»ƒé€Ÿåº¦
    workers=8,                  # æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°
    amp=True,                   # è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒï¼ŒèŠ‚çœæ˜¾å­˜
    
    # === è®­ç»ƒæ§åˆ¶å‚æ•° ===
    patience=30,                # æ—©åœè€å¿ƒå€¼ï¼Œ30ä¸ªepochæ— æ”¹å–„ååœæ­¢
    save_period=25,             # æ¯25ä¸ªepochä¿å­˜ä¸€æ¬¡æ¨¡å‹
    val=True,                   # è®­ç»ƒæœŸé—´è¿›è¡ŒéªŒè¯
    plots=True,                 # ç”Ÿæˆè®­ç»ƒå›¾è¡¨å’Œå¯è§†åŒ–
    verbose=True,               # è¯¦ç»†è¾“å‡ºè®­ç»ƒä¿¡æ¯
    
    # === å­¦ä¹ ç‡å’Œä¼˜åŒ–å™¨ ===
    lr0=0.01,                   # åˆå§‹å­¦ä¹ ç‡
    lrf=0.01,                   # æœ€ç»ˆå­¦ä¹ ç‡ = lr0 * lrf
    momentum=0.937,             # SGDåŠ¨é‡
    weight_decay=0.0005,        # æƒé‡è¡°å‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
    warmup_epochs=3.0,          # å­¦ä¹ ç‡é¢„çƒ­è½®æ•°
    cos_lr=False,               # æ˜¯å¦ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦
    
    # === æ•°æ®å¢å¼ºå‚æ•° ===
    hsv_h=0.015,                # è‰²è°ƒå¢å¼ºèŒƒå›´
    hsv_s=0.7,                  # é¥±å’Œåº¦å¢å¼ºèŒƒå›´
    hsv_v=0.4,                  # æ˜åº¦å¢å¼ºèŒƒå›´
    degrees=0.0,                # æ—‹è½¬è§’åº¦èŒƒå›´ (+/-deg)
    translate=0.1,              # å¹³ç§»èŒƒå›´ (+/-fraction)
    scale=0.5,                  # ç¼©æ”¾èŒƒå›´ (+/-gain)
    fliplr=0.5,                 # æ°´å¹³ç¿»è½¬æ¦‚ç‡
    mosaic=1.0,                 # é©¬èµ›å…‹å¢å¼ºæ¦‚ç‡
    mixup=0.0,                  # æ··åˆå¢å¼ºæ¦‚ç‡
    
    # === æŸå¤±å‡½æ•°æƒé‡ ===
    box=7.5,                    # è¾¹ç•Œæ¡†æŸå¤±æƒé‡
    cls=0.5,                    # åˆ†ç±»æŸå¤±æƒé‡
    dfl=1.5,                    # DFLæŸå¤±æƒé‡ # å¯èƒ½åœ¨trainä¸­ä¸èµ·ä½œç”¨ï¼Œå› ä¸ºè¾“å‡º84é€šé“æ²¡æœ‰DFLæ•°æ®
    
    # === é¡¹ç›®ç®¡ç† ===
    project='yolo_training',    # é¡¹ç›®ç›®å½•åç§°
    name='coco8_run',           # å®éªŒåç§°
    
    # === é«˜çº§è®¾ç½® ===
    seed=42,                    # éšæœºç§å­ï¼Œä¿è¯å¯é‡å¤æ€§
    deterministic=True,         # ç¡®å®šæ€§è®­ç»ƒ
    resume=False,               # æ˜¯å¦ä»ä¸Šæ¬¡æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
)

print(f"\nè®­ç»ƒå®Œæˆï¼æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {train_results}")

# Evaluate the model's performance on the validation set
print("\nå¼€å§‹éªŒè¯æ¨¡å‹æ€§èƒ½...")
metrics = model.val()
print(f"mAP50: {metrics.box.map50:.4f}")
print(f"mAP50-95: {metrics.box.map:.4f}")

# Perform object detection on an image
print("\næµ‹è¯•å›¾åƒé¢„æµ‹...")
try:
    results = model("test_image.jpg")  # Predict on an image
    results[0].show()  # Display results
    print("é¢„æµ‹å®Œæˆï¼Œç»“æœå·²æ˜¾ç¤º")
    
    # === æŸ¥çœ‹æ¨¡å‹çš„ç›´æ¥è¾“å‡ºæ•°æ® ===
    print("\n=== æ¨¡å‹ç›´æ¥è¾“å‡ºæ•°æ®åˆ†æ ===")
    
    # è·å–åŸå§‹PyTorchæ¨¡å‹
    raw_model = model.model
    
    # å‡†å¤‡è¾“å…¥æ•°æ®ï¼ˆæ¨¡æ‹ŸYOLOé¢„å¤„ç†ï¼‰
    import cv2
    img = cv2.imread("test_image.jpg")
    if img is not None:
        print(f"åŸå§‹å›¾åƒå°ºå¯¸: {img.shape}")
        
        # YOLOé¢„å¤„ç†
        img_resized = cv2.resize(img, (640, 640))
        img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0
        img_tensor = img_tensor.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
        
        # ç¡®ä¿å¼ é‡åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼ˆGPUæˆ–CPUï¼‰
        device = next(raw_model.parameters()).device
        img_tensor = img_tensor.to(device)
        
        print(f"é¢„å¤„ç†åå¼ é‡å½¢çŠ¶: {img_tensor.shape}")
        print(f"å¼ é‡è®¾å¤‡: {img_tensor.device}")
        print(f"æ¨¡å‹è®¾å¤‡: {device}")
        
        # è·å–æ¨¡å‹åŸå§‹è¾“å‡º
        with torch.no_grad():
            raw_outputs = raw_model(img_tensor)
        
        print(f"\næ¨¡å‹åŸå§‹è¾“å‡ºä¿¡æ¯:")
        print(f"è¾“å‡ºæ•°é‡: {len(raw_outputs)}")
        
        for i, output in enumerate(raw_outputs):
            # æ£€æŸ¥è¾“å‡ºç±»å‹
            if isinstance(output, torch.Tensor):
                print(f"è¾“å‡º {i}: å¼ é‡ï¼Œå½¢çŠ¶ {output.shape}")
                print(f"  æ•°æ®ç±»å‹: {output.dtype}")
                print(f"  è®¾å¤‡: {output.device}")
                print(f"  æ•°å€¼èŒƒå›´: [{output.min().item():.6f}, {output.max().item():.6f}]")
                print(f"  å¹³å‡å€¼: {output.mean().item():.6f}")
            elif isinstance(output, list):
                print(f"è¾“å‡º {i}: åˆ—è¡¨ï¼ŒåŒ…å« {len(output)} ä¸ªå…ƒç´ ")
                for j, item in enumerate(output):
                    if isinstance(item, torch.Tensor):
                        print(f"  åˆ—è¡¨å…ƒç´  {j}: å¼ é‡ï¼Œå½¢çŠ¶ {item.shape}")
                        print(f"    æ•°æ®ç±»å‹: {item.dtype}")
                        print(f"    è®¾å¤‡: {item.device}")
                        print(f"    æ•°å€¼èŒƒå›´: [{item.min().item():.6f}, {item.max().item():.6f}]")
                        print(f"    å¹³å‡å€¼: {item.mean().item():.6f}")
                    else:
                        print(f"  åˆ—è¡¨å…ƒç´  {j}: ç±»å‹ {type(item)}")
            else:
                print(f"è¾“å‡º {i}: æœªçŸ¥ç±»å‹ {type(output)}")
            
            # è¯¦ç»†åˆ†æä¸»è¦è¾“å‡ºå¼ é‡
            if i == 0 and isinstance(output, torch.Tensor):  # ä¸»è¦æ£€æµ‹è¾“å‡º
                try:
                    if len(output.shape) == 3:
                        batch_size, channels, num_anchors = output.shape
                        print(f"\n=== ä¸»è¦è¾“å‡ºå¼ é‡è¯¦ç»†åˆ†æ ===")
                        print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
                        print(f"ç‰¹å¾é€šé“æ•°: {channels} (åŒ…å«åæ ‡+ç±»åˆ«+å…¶ä»–ç‰¹å¾)")
                        print(f"é”šç‚¹æ€»æ•°: {num_anchors}")
                        
                        # åˆ†æä¸åŒéƒ¨åˆ†çš„æ•°æ®
                        output_data = output[0]  # å»é™¤batchç»´åº¦
                        
                        # åæ ‡ä¿¡æ¯ (å‰4ä¸ªé€šé“)
                        if channels >= 4:
                            coords = output_data[:4, :]
                            print(f"\nåæ ‡ä¿¡æ¯ (å‰4ä¸ªé€šé“):")
                            print(f"  Xåæ ‡èŒƒå›´: [{coords[0].min().item():.3f}, {coords[0].max().item():.3f}]")
                            print(f"  Yåæ ‡èŒƒå›´: [{coords[1].min().item():.3f}, {coords[1].max().item():.3f}]")
                            print(f"  å®½åº¦èŒƒå›´: [{coords[2].min().item():.3f}, {coords[2].max().item():.3f}]")
                            print(f"  é«˜åº¦èŒƒå›´: [{coords[3].min().item():.3f}, {coords[3].max().item():.3f}]")
                        
                        # ç±»åˆ«æ¦‚ç‡ä¿¡æ¯ (COCOæœ‰80ä¸ªç±»åˆ«)
                        if channels >= 84:  # 4ä¸ªåæ ‡ + 80ä¸ªç±»åˆ«
                            class_probs = output_data[4:84, :]
                            print(f"\nç±»åˆ«æ¦‚ç‡ä¿¡æ¯ (80ä¸ªCOCOç±»åˆ«):")
                            print(f"  æ¦‚ç‡èŒƒå›´: [{class_probs.min().item():.6f}, {class_probs.max().item():.6f}]")
                            print(f"  å¹³å‡æ¦‚ç‡: {class_probs.mean().item():.6f}")
                            
                            # æ‰¾åˆ°ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹
                            max_class_scores, max_class_indices = torch.max(class_probs, dim=0)
                            top_conf_idx = torch.argmax(max_class_scores)
                            
                            print(f"\nç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹:")
                            print(f"  é”šç‚¹ç´¢å¼•: {top_conf_idx.item()}")
                            print(f"  æœ€é«˜ç½®ä¿¡åº¦: {max_class_scores[top_conf_idx].item():.6f}")
                            print(f"  é¢„æµ‹ç±»åˆ«ID: {max_class_indices[top_conf_idx].item()}")
                            if channels >= 4:
                                print(f"  å¯¹åº”åæ ‡: x={coords[0, top_conf_idx].item():.3f}, "
                                      f"y={coords[1, top_conf_idx].item():.3f}, "
                                      f"w={coords[2, top_conf_idx].item():.3f}, "
                                      f"h={coords[3, top_conf_idx].item():.3f}")
                        
                        # é”šç‚¹åˆ†å¸ƒåˆ†æ
                        print(f"\né”šç‚¹åˆ†å¸ƒåˆ†æ:")
                        print(f"8400ä¸ªé”šç‚¹æ¥è‡ªä¸åŒå°ºåº¦çš„ç‰¹å¾å›¾:")
                        print(f"  - 80Ã—80 ç‰¹å¾å›¾: 6400ä¸ªé”šç‚¹ (ç»†ç²’åº¦æ£€æµ‹)")
                        print(f"  - 40Ã—40 ç‰¹å¾å›¾: 1600ä¸ªé”šç‚¹ (ä¸­ç­‰å°ºåº¦æ£€æµ‹)")
                        print(f"  - 20Ã—20 ç‰¹å¾å›¾: 400ä¸ªé”šç‚¹ (å¤§ç›®æ ‡æ£€æµ‹)")
                        print(f"  æ€»è®¡: 6400 + 1600 + 400 = 8400 ä¸ªé”šç‚¹")
                    else:
                        print(f"\nâš ï¸  è¾“å‡ºå¼ é‡ç»´åº¦ä¸ç¬¦åˆé¢„æœŸ: {output.shape}")
                        print("   é¢„æœŸ: 3ç»´å¼ é‡ [batch_size, channels, num_anchors]")
                        
                except Exception as e:
                    print(f"\nâŒ åˆ†æä¸»è¦è¾“å‡ºå¼ é‡æ—¶å‡ºé”™: {e}")
                    print(f"   è¾“å‡ºå¼ é‡å½¢çŠ¶: {output.shape}")
                    print(f"   è¾“å‡ºå¼ é‡ç±»å‹: {type(output)}")
        
        print(f"\n=== YOLO11åŒè¾“å‡ºç»“æ„è¯´æ˜ ===")
        print("ğŸ¯ è¾“å‡º0: ä¸»è¦æ£€æµ‹ç»“æœ")
        print("  - å½¢çŠ¶: [1, 84, 8400]")
        print("  - 84ä¸ªé€šé“ = 4ä¸ªåæ ‡ç‰¹å¾ + 80ä¸ªç±»åˆ«æ¦‚ç‡")
        print("  - 8400ä¸ªé”šç‚¹æ¥è‡ª3ä¸ªå°ºåº¦ç‰¹å¾å›¾çš„åˆå¹¶")
        print("  - ç”¨æˆ·å‹å¥½çš„ç®€åŒ–è¾“å‡º")
        print()
        print("ğŸ¯ è¾“å‡º1: åŸå§‹ç‰¹å¾å›¾åˆ—è¡¨")
        print("  - åŒ…å«3ä¸ªå¼ é‡çš„åˆ—è¡¨")
        print("  - å¼ é‡0: [1, 144, 80, 80] - é«˜åˆ†è¾¨ç‡ç‰¹å¾")
        print("  - å¼ é‡1: [1, 144, 40, 40] - ä¸­åˆ†è¾¨ç‡ç‰¹å¾") 
        print("  - å¼ é‡2: [1, 144, 20, 20] - ä½åˆ†è¾¨ç‡ç‰¹å¾")
        print("  - 144ä¸ªé€šé“åŒ…å«å®Œæ•´è®­ç»ƒç‰¹å¾(å«DFL)")
        print("  - ç”¨äºè°ƒè¯•å’Œé«˜çº§åº”ç”¨")
        print()
        print("=== åå¤„ç†ç®—æ³•è¯´æ˜ ===")
        print("1. ç½®ä¿¡åº¦è¿‡æ»¤: ä¿ç•™ç½®ä¿¡åº¦ > threshold çš„æ£€æµ‹")
        print("2. åæ ‡è§£ç : å°†ç›¸å¯¹åæ ‡è½¬æ¢ä¸ºç»å¯¹åƒç´ åæ ‡")
        print("3. NMS(éæå¤§å€¼æŠ‘åˆ¶): ç§»é™¤é‡å çš„æ£€æµ‹æ¡†")
        print("4. åæ ‡ç¼©æ”¾: å°†640Ã—640å°ºå¯¸çš„åæ ‡ç¼©æ”¾åˆ°åŸå›¾å°ºå¯¸")
        
    else:
        print("æ— æ³•è¯»å–æµ‹è¯•å›¾åƒï¼Œè·³è¿‡ç›´æ¥è¾“å‡ºåˆ†æ")
        
except Exception as e:
    print(f"é¢„æµ‹å¤±è´¥: {e}")
    print("æç¤º: è¯·ç¡®ä¿test_image.jpgæ–‡ä»¶å­˜åœ¨")

# Export the model to ONNX format for deployment
print("\nå¯¼å‡ºONNXæ¨¡å‹...")
try:
    path = model.export(format="onnx")  # Returns the path to the exported model
    print(f"ONNXæ¨¡å‹å·²å¯¼å‡ºåˆ°: {path}")
except Exception as e:
    print(f"å¯¼å‡ºå¤±è´¥: {e}")

print("\n=== è®­ç»ƒæµç¨‹å®Œæˆ ===")
print("æ£€æŸ¥ä»¥ä¸‹ç›®å½•è·å–è®­ç»ƒç»“æœ:")
print("- yolo_training/coco8_run/weights/ (æ¨¡å‹æƒé‡)")
print("- yolo_training/coco8_run/ (è®­ç»ƒå›¾è¡¨å’Œæ—¥å¿—)")
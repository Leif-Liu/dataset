import whisper
import numpy as np
import sounddevice as sd
import queue
import threading
import sys

# é…ç½®å‚æ•°
SAMPLE_RATE = 16000  # Whisper ä½¿ç”¨ 16kHz é‡‡æ ·ç‡
CHUNK_DURATION = 5   # æ¯ 5 ç§’å¤„ç†ä¸€æ¬¡éŸ³é¢‘
CHUNK_SIZE = SAMPLE_RATE * CHUNK_DURATION

# åŠ è½½ Whisper æ¨¡å‹
print("æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹...")
model = whisper.load_model("large")
print("æ¨¡å‹åŠ è½½å®Œæˆï¼")

# éŸ³é¢‘é˜Ÿåˆ—
audio_queue = queue.Queue()

def audio_callback(indata, frames, time, status):
    """éŸ³é¢‘è¾“å…¥å›è°ƒå‡½æ•°"""
    if status:
        print(f"éŸ³é¢‘çŠ¶æ€: {status}", file=sys.stderr)
    # å°†éŸ³é¢‘æ•°æ®æ”¾å…¥é˜Ÿåˆ—
    audio_queue.put(indata.copy())

def transcribe_audio(audio_data):


    """è½¬å½•éŸ³é¢‘æ•°æ® - ä½¿ç”¨é«˜çº§ APIï¼Œè‡ªåŠ¨å¤„ç†ä»»æ„é•¿åº¦"""
    try:
        # å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º float32 å¹¶å±•å¹³
        audio = audio_data.flatten().astype(np.float32)
        
        # ä½¿ç”¨ model.transcribe() æ–¹æ³•
        # ä¼˜ç‚¹ï¼š
        # 1. è‡ªåŠ¨å¤„ç†ä»»æ„é•¿åº¦çš„éŸ³é¢‘ï¼ˆä¸éœ€è¦æ‰‹åŠ¨ pad/trimï¼‰
        # 2. å¯¹äºé•¿éŸ³é¢‘ä¼šè‡ªåŠ¨åˆ†æ®µå¤„ç†
        # 3. è¿”å›å®Œæ•´çš„è½¬å½•ç»“æœï¼ŒåŒ…æ‹¬æ—¶é—´æˆ³ç­‰ä¿¡æ¯
        result = model.transcribe(
            audio,
            language=None,  # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
            fp16=True,      # ä½¿ç”¨ FP16 åŠ é€Ÿï¼ˆå¦‚æœæœ‰ GPUï¼‰
            verbose=False   # ä¸æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        )
        
        return result['text'], result['language']
        
    except Exception as e:
        print(f"è½¬å½•é”™è¯¯: {e}")
        return None, None

def process_audio():
    """å¤„ç†éŸ³é¢‘é˜Ÿåˆ—ä¸­çš„æ•°æ®"""
    audio_buffer = []
    
    while True:
        try:
            # ä»é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®
            chunk = audio_queue.get()
            audio_buffer.append(chunk)
            
            # å½“ç¼“å†²åŒºç´¯ç§¯åˆ°æŒ‡å®šæ—¶é•¿æ—¶è¿›è¡Œè½¬å½•
            if len(audio_buffer) * len(audio_buffer[0]) >= CHUNK_SIZE:
                # åˆå¹¶éŸ³é¢‘æ•°æ®
                audio_data = np.concatenate(audio_buffer)
                
                # è½¬å½•
                text, lang = transcribe_audio(audio_data)
                
                if text and text.strip():
                    print(f"\n[{lang}] {text}")
                    print("-" * 50)
                
                # æ¸…ç©ºç¼“å†²åŒº
                audio_buffer = []
                
        except KeyboardInterrupt:
            break

def main():
    """ä¸»å‡½æ•°"""
    print(f"\nå¼€å§‹å®æ—¶è¯­éŸ³è½¬å½• (ä¼˜åŒ–ç‰ˆæœ¬)...")
    print(f"é‡‡æ ·ç‡: {SAMPLE_RATE} Hz")
    print(f"å¤„ç†é—´éš”: {CHUNK_DURATION} ç§’")
    print(f"ä½¿ç”¨é«˜çº§ API - è‡ªåŠ¨å¤„ç†ä»»æ„é•¿åº¦éŸ³é¢‘")
    print(f"æŒ‰ Ctrl+C åœæ­¢\n")
    print("=" * 50)
    
    # å¯åŠ¨éŸ³é¢‘å¤„ç†çº¿ç¨‹
    processing_thread = threading.Thread(target=process_audio, daemon=True)
    processing_thread.start()
    
    try:
        # å¼€å§‹å½•éŸ³
        with sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=1,  # å•å£°é“
            callback=audio_callback,
            blocksize=int(SAMPLE_RATE * 0.5)  # æ¯ 0.5 ç§’å›è°ƒä¸€æ¬¡
        ):
            print("ğŸ¤ æ­£åœ¨ç›‘å¬éº¦å…‹é£...")
            # ä¿æŒè¿è¡Œ
            processing_thread.join()
    except KeyboardInterrupt:
        print("\n\nåœæ­¢å½•éŸ³...")
    except Exception as e:
        print(f"\né”™è¯¯: {e}")

if __name__ == "__main__":
    main()

